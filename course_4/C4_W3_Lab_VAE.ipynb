{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "C4_W3_Lab_VAE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOQBbuOy5BJ/EpchcKbfCvC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "afbec413727f4b9d8e7eca98a0e56232": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e61785dbdd174eab98ec8e79557cd5fc",
              "IPY_MODEL_f4004a8dab78405f8c7eab897b70e7f8",
              "IPY_MODEL_f136d09b036a443282d5480d94ba463d"
            ],
            "layout": "IPY_MODEL_476e84229f174b92883198a64ebcc047"
          }
        },
        "e61785dbdd174eab98ec8e79557cd5fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c9bdb86869d427692b7a9e32172992e",
            "placeholder": "​",
            "style": "IPY_MODEL_2ca972244d2a403c81ea769126c92ecb",
            "value": "Dl Completed...: 100%"
          }
        },
        "f4004a8dab78405f8c7eab897b70e7f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61f0a588c8f046389a246c00c5e24cee",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b15cf34929e44882a2fd465c18923dac",
            "value": 4
          }
        },
        "f136d09b036a443282d5480d94ba463d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66d9bf59f10e4d8180dc611272d42313",
            "placeholder": "​",
            "style": "IPY_MODEL_392ea67480cb445287addf246434c4d4",
            "value": " 4/4 [00:00&lt;00:00,  6.26 file/s]"
          }
        },
        "476e84229f174b92883198a64ebcc047": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c9bdb86869d427692b7a9e32172992e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ca972244d2a403c81ea769126c92ecb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61f0a588c8f046389a246c00c5e24cee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b15cf34929e44882a2fd465c18923dac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "66d9bf59f10e4d8180dc611272d42313": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "392ea67480cb445287addf246434c4d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ksairos/tf-advanced-techniques-course/blob/main/course_4/C4_W3_Lab_VAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Variational AutoEncoder"
      ],
      "metadata": {
        "id": "YNNEothgohei"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Variational AutoEncoder on MNIST dataset to generate new images of digits"
      ],
      "metadata": {
        "id": "azbXHTRrooiS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "voABFfGXoxoI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "_7G6_lztoXr3"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "\n",
        "K = tf.keras.backend"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parameters"
      ],
      "metadata": {
        "id": "3UTM6KHMozoR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 128\n",
        "LATENT_DIM = 2"
      ],
      "metadata": {
        "id": "KNafECwsog84"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare Dataset"
      ],
      "metadata": {
        "id": "EWS2jH2Oo529"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Utilities\n",
        "\n",
        "def map_image(image, label):\n",
        "  '''returns a normalized and reshaped tensor from a given image'''\n",
        "  image = tf.cast(image, dtype=tf.float32)\n",
        "  image = image / 255.0\n",
        "  image = tf.reshape(image, shape=(28, 28, 1,))\n",
        "  \n",
        "  return image\n",
        "\n",
        "\n",
        "def get_dataset(map_fn, is_validation=False):\n",
        "  '''Loads and prepares the mnist dataset from TFDS.'''\n",
        "  if is_validation:\n",
        "    split_name = \"test\"\n",
        "  else:\n",
        "    split_name = \"train\"\n",
        "\n",
        "  dataset = tfds.load('mnist', as_supervised=True, split=split_name)\n",
        "  dataset = dataset.map(map_fn)\n",
        "  \n",
        "  if is_validation:\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "  else:\n",
        "    dataset = dataset.shuffle(1024).batch(BATCH_SIZE)\n",
        "\n",
        "  return dataset"
      ],
      "metadata": {
        "id": "-a7k7lxFo48f"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = get_dataset(map_image)\n",
        "valid_dataset = get_dataset(map_image, is_validation=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217,
          "referenced_widgets": [
            "afbec413727f4b9d8e7eca98a0e56232",
            "e61785dbdd174eab98ec8e79557cd5fc",
            "f4004a8dab78405f8c7eab897b70e7f8",
            "f136d09b036a443282d5480d94ba463d",
            "476e84229f174b92883198a64ebcc047",
            "7c9bdb86869d427692b7a9e32172992e",
            "2ca972244d2a403c81ea769126c92ecb",
            "61f0a588c8f046389a246c00c5e24cee",
            "b15cf34929e44882a2fd465c18923dac",
            "66d9bf59f10e4d8180dc611272d42313",
            "392ea67480cb445287addf246434c4d4"
          ]
        },
        "id": "C4cjqPTkpBML",
        "outputId": "b2cf3275-4424-48e8-8e70-b5903a7e3bf4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mDownloading and preparing dataset mnist/3.0.1 (download: 11.06 MiB, generated: 21.00 MiB, total: 32.06 MiB) to /root/tensorflow_datasets/mnist/3.0.1...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Dataset mnist is hosted on GCS. It will automatically be downloaded to your\n",
            "local data directory. If you'd instead prefer to read directly from our public\n",
            "GCS bucket (recommended if you're running on GCP), you can instead pass\n",
            "`try_gcs=True` to `tfds.load` or set `data_dir=gs://tfds-data/datasets`.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dl Completed...:   0%|          | 0/4 [00:00<?, ? file/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "afbec413727f4b9d8e7eca98a0e56232"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\u001b[1mDataset mnist downloaded and prepared to /root/tensorflow_datasets/mnist/3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the model"
      ],
      "metadata": {
        "id": "2eq-nrmYpVDm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1YAZAeMGEJ1KgieYk1ju-S9DoshpMREeC\" width=\"60%\" height=\"60%\"/>"
      ],
      "metadata": {
        "id": "P2veDGaLp7BU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Architecture of VAE is similar to general auto-encoders with main difference in latent representation. It takes output of the encoder and mixes it with a random sample, letting us generate something new."
      ],
      "metadata": {
        "id": "5t1yUzjyqiI9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sampling Class"
      ],
      "metadata": {
        "id": "jgKa1e2YqRWN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Custom layer that defines a gray box in the diagram"
      ],
      "metadata": {
        "id": "-jiOswL1qu9z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Sampling(tf.keras.layers.Layer):\n",
        "  def call(self, input):\n",
        "    \"\"\"Generates a random sample and combines with the encoder output\n",
        "\n",
        "    Args:\n",
        "      inputs -- output tensor from the encoder\n",
        "\n",
        "    Returns:\n",
        "      `inputs` tensors combined with a random sample\n",
        "    \"\"\"\n",
        "\n",
        "    # unpack the output of the encoder \n",
        "    mu, sigma = input\n",
        "\n",
        "    # get the size and dimentions of the batch\n",
        "    batch = tf.shape(mu)[0]\n",
        "    dim = tf.shape(mu)[1]\n",
        "\n",
        "    # generate a random tensor\n",
        "    epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
        "\n",
        "    # mix the inputs and generated noise\n",
        "    return mu + tf.exp(0.5 * sigma) * epsilon"
      ],
      "metadata": {
        "id": "dGpPr_plpPpS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Encoder"
      ],
      "metadata": {
        "id": "h3OFjcuKtW_O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1eoxFK_UVSHd3a_5EHcCU8F8QDZlPiXfW\" width=\"60%\" height=\"60%\"/>"
      ],
      "metadata": {
        "id": "4UlLX6j9taPT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Dense, Conv2D, BatchNormalization, Flatten, Input, Reshape, Conv2DTranspose\n",
        "\n",
        "def encoder_layers(inputs, latent_dim):\n",
        "  \"\"\"Defines the encoder's layers.\n",
        "  Args:\n",
        "    inputs -- batch from the dataset\n",
        "    latent_dim -- dimensionality of the latent space\n",
        "\n",
        "  Returns:\n",
        "    mu -- learned mean\n",
        "    sigma -- learned standard deviation\n",
        "    batch_2.shape -- shape of the features before flattening\n",
        "  \"\"\" \n",
        "\n",
        "  # Conv2D layers followed by BatchNormalization layers\n",
        "  x = Conv2D(filters=32, kernel_size=3, strides=2, padding='same', activation='relu', name='encoder_conv1')(inputs)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Conv2D(filters=64, kernel_size=3, strides=2, padding='same', activation='relu', name='encoder_conv2')(x)\n",
        "\n",
        "  # this will be our third output\n",
        "  batch_2 = BatchNormalization()(x)\n",
        "\n",
        "  # Flatten before feeding to Dense layer\n",
        "  x = Flatten(name=\"encoder_flatten\")(batch_2)\n",
        "\n",
        "  # Dense layer\n",
        "  x = Dense(20, activation='relu', name='encoder_dense')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "\n",
        "  # Dense layers for mu and sigma with latent_dim units\n",
        "  mu = Dense(latent_dim, name='latent_mu')(x)\n",
        "  sigma = Dense(latent_dim, name='latent_sigma')(x)\n",
        "\n",
        "  return mu, sigma, batch_2.shape"
      ],
      "metadata": {
        "id": "He_iqqCDtV72"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encoder_model(latent_dim, input_shape):\n",
        "  \"\"\"Defines the encoder model with the Sampling layer\n",
        "  Args:\n",
        "    latent_dim -- dimensionality of the latent space\n",
        "    input_shape -- shape of the dataset batch\n",
        "\n",
        "  Returns:\n",
        "    model -- the encoder model\n",
        "    conv_shape -- shape of the features before flattening\n",
        "  \"\"\"\n",
        "\n",
        "  # input layer\n",
        "  inputs = Input(shape=input_shape)\n",
        "\n",
        "  # get the output of encoder layers\n",
        "  mu, sigma, conv_shape = encoder_layers(inputs, latent_dim)\n",
        "\n",
        "  # feed mu and sigma to Sampling layer\n",
        "  z = Sampling()((mu, sigma))\n",
        "\n",
        "  # build encoder model\n",
        "  model = tf.keras.Model(inputs=inputs, outputs=[mu, sigma, z])\n",
        "\n",
        "  return model, conv_shape"
      ],
      "metadata": {
        "id": "PQX8fIZJvzem"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "K.clear_session()\n",
        "\n",
        "tmp_encoder, _ = encoder_model(LATENT_DIM, (28, 28, 1))\n",
        "tmp_encoder.summary()\n",
        "\n",
        "del tmp_encoder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itq10ArAIDzt",
        "outputId": "f0d77d8f-507d-42e9-c921-dd51acb6418c"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 28, 28, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " encoder_conv1 (Conv2D)         (None, 14, 14, 32)   320         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 14, 14, 32)  128         ['encoder_conv1[0][0]']          \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " encoder_conv2 (Conv2D)         (None, 7, 7, 64)     18496       ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 7, 7, 64)    256         ['encoder_conv2[0][0]']          \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " encoder_flatten (Flatten)      (None, 3136)         0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " encoder_dense (Dense)          (None, 20)           62740       ['encoder_flatten[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 20)          80          ['encoder_dense[0][0]']          \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " latent_mu (Dense)              (None, 2)            42          ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " latent_sigma (Dense)           (None, 2)            42          ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " sampling (Sampling)            (None, 2)            0           ['latent_mu[0][0]',              \n",
            "                                                                  'latent_sigma[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 82,104\n",
            "Trainable params: 81,872\n",
            "Non-trainable params: 232\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decoder\n",
        "This part of the model expands latent representations back to original size image. It will resemble training data"
      ],
      "metadata": {
        "id": "uTIPB_FVHGYd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decoder_layers(inputs, conv_shape):\n",
        "  \"\"\"Defines the decoder layers.\n",
        "  Args:\n",
        "    inputs -- output of the encoder \n",
        "    conv_shape -- shape of the features before flattening\n",
        "\n",
        "  Returns:\n",
        "    tensor containing the decoded output\n",
        "  \"\"\"\n",
        "\n",
        "  # Compute number of units from conv_shape dimentions and create a Dense layer\n",
        "  units = conv_shape[1] * conv_shape[2] * conv_shape[3]\n",
        "  x = Dense(units, activation='relu', name='decoder_dense')(inputs)\n",
        "  x = BatchNormalization()(x)\n",
        "\n",
        "  # Reshape resulting dense layer into conv_shape\n",
        "  x = Reshape((conv_shape[1], conv_shape[2], conv_shape[3]), name=\"decoder_reshape\")(x)\n",
        "\n",
        "  # Upsample back to original size with deconvolutional layers\n",
        "  x = Conv2DTranspose(filters=64, kernel_size=3, strides=2, padding='same', activation='relu', name='decoder_deconv2d_1')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Conv2DTranspose(filters=32, kernel_size=3, strides=2, padding='same', activation='relu', name='decoder_deconv2d_2')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Conv2DTranspose(filters=1, kernel_size=3, strides=1, padding='same', activation='relu', name='decoder_deconv2d_final')(x)\n",
        "\n",
        "  return x"
      ],
      "metadata": {
        "id": "YXMNhduFw5vc"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decoder_model(latent_dim, conv_shape):\n",
        "  \"\"\"Defines the decoder model.\n",
        "  Args:\n",
        "    latent_dim -- dimensionality of the latent space\n",
        "    conv_shape -- shape of the features before flattening\n",
        "\n",
        "  Returns:\n",
        "    model -- the decoder model\n",
        "  \"\"\"\n",
        "\n",
        "  inputs = Input(shape=(latent_dim, ))\n",
        "\n",
        "  outputs = decoder_layers(inputs, conv_shape)\n",
        "\n",
        "  model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "ZrMzkVLoMHRw"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "K.clear_session()\n",
        "\n",
        "tmp_decoder = decoder_model(LATENT_DIM, (None, 7, 7, 64))\n",
        "tmp_decoder.summary()\n",
        "\n",
        "del tmp_decoder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQqFoHahNE2j",
        "outputId": "5db6f3c5-be73-47d3-ebb3-64492f25002c"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 2)]               0         \n",
            "                                                                 \n",
            " decoder_dense (Dense)       (None, 3136)              9408      \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 3136)             12544     \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " decoder_reshape (Reshape)   (None, 7, 7, 64)          0         \n",
            "                                                                 \n",
            " decoder_deconv2d_1 (Conv2DT  (None, 14, 14, 64)       36928     \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 14, 14, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " decoder_deconv2d_2 (Conv2DT  (None, 28, 28, 32)       18464     \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 28, 28, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " decoder_deconv2d_final (Con  (None, 28, 28, 1)        289       \n",
            " v2DTranspose)                                                   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 78,017\n",
            "Trainable params: 71,553\n",
            "Non-trainable params: 6,464\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Kullback–Leibler Divergence\n",
        "We add Kullback–Leibler Divergence to our reconstruction loss in order to improve generative capabilities of our model"
      ],
      "metadata": {
        "id": "ntJHNecHSF-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def kl_reconstruction_loss(inputs, outputs, mu, sigma):\n",
        "  \"\"\" Computes the Kullback-Leibler Divergence (KLD)\n",
        "  Args:\n",
        "    inputs -- batch from the dataset\n",
        "    outputs -- output of the Sampling layer\n",
        "    mu -- mean\n",
        "    sigma -- standard deviation\n",
        "\n",
        "  Returns:\n",
        "    KLD loss\n",
        "  \"\"\"\n",
        "  kl_loss = 1 + sigma - tf.square(mu) - tf.math.exp(sigma)\n",
        "  kl_loss = tf.reduce_mean(kl_loss) * -0.5\n",
        "  \n",
        "  return kl_loss"
      ],
      "metadata": {
        "id": "jDwXztAzNOd2"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Entire VAE Model"
      ],
      "metadata": {
        "id": "fwHAMn6zSyeX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def vae_model(encoder, decoder, input_shape):\n",
        "  \"\"\"Defines the VAE model\n",
        "  Args:\n",
        "    encoder -- the encoder model\n",
        "    decoder -- the decoder model\n",
        "    input_shape -- shape of the dataset batch\n",
        "\n",
        "  Returns:\n",
        "    the complete VAE model\n",
        "  \"\"\"\n",
        "\n",
        "  # input\n",
        "  inputs = Input(input_shape)\n",
        "  \n",
        "  # encoder outputs\n",
        "  mu, sigma, z = encoder(inputs)\n",
        "\n",
        "  # reconstructed output from the decoder   \n",
        "  reconstructed = decoder(z)\n",
        "\n",
        "  # define the model\n",
        "  model = tf.keras.Model(inputs=inputs, outputs=reconstructed)\n",
        "\n",
        "  # add the KL loss \n",
        "  loss = kl_reconstruction_loss(inputs, z, mu, sigma)\n",
        "  model.add_loss(loss)\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "_izc55SmSphE"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, the function that combines everything we were writing"
      ],
      "metadata": {
        "id": "-yWfHCCzUgy4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_models(input_shape, latent_dim):\n",
        "  \"\"\"Returns the encoder, decoder, and vae models\"\"\"\n",
        "  encoder, conv_shape = encoder_model(latent_dim, input_shape)\n",
        "  decoder = decoder_model(latent_dim, conv_shape)\n",
        "  vae = vae_model(encoder, decoder, input_shape)\n",
        "  \n",
        "  return encoder, decoder, vae"
      ],
      "metadata": {
        "id": "YmDBe9oMUa7S"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "K.clear_session()\n",
        "\n",
        "encoder, decoder, vae = get_models(input_shape=(28,28,1), latent_dim=LATENT_DIM)"
      ],
      "metadata": {
        "id": "mi1RBx4UVFud"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vae.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mqDi2TLVLrh",
        "outputId": "311424e8-8295-4b34-9cbc-dbca46b1533b"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 28, 28, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " model (Functional)             [(None, 2),          82104       ['input_3[0][0]']                \n",
            "                                 (None, 2),                                                       \n",
            "                                 (None, 2)]                                                       \n",
            "                                                                                                  \n",
            " model_1 (Functional)           (None, 28, 28, 1)    78017       ['model[0][2]']                  \n",
            "                                                                                                  \n",
            " tf.__operators__.add (TFOpLamb  (None, 2)           0           ['model[0][1]']                  \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " tf.math.square (TFOpLambda)    (None, 2)            0           ['model[0][0]']                  \n",
            "                                                                                                  \n",
            " tf.math.subtract (TFOpLambda)  (None, 2)            0           ['tf.__operators__.add[0][0]',   \n",
            "                                                                  'tf.math.square[0][0]']         \n",
            "                                                                                                  \n",
            " tf.math.exp (TFOpLambda)       (None, 2)            0           ['model[0][1]']                  \n",
            "                                                                                                  \n",
            " tf.math.subtract_1 (TFOpLambda  (None, 2)           0           ['tf.math.subtract[0][0]',       \n",
            " )                                                                'tf.math.exp[0][0]']            \n",
            "                                                                                                  \n",
            " tf.math.reduce_mean (TFOpLambd  ()                  0           ['tf.math.subtract_1[0][0]']     \n",
            " a)                                                                                               \n",
            "                                                                                                  \n",
            " tf.math.multiply (TFOpLambda)  ()                   0           ['tf.math.reduce_mean[0][0]']    \n",
            "                                                                                                  \n",
            " add_loss (AddLoss)             ()                   0           ['tf.math.multiply[0][0]']       \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 160,121\n",
            "Trainable params: 153,425\n",
            "Non-trainable params: 6,696\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the model"
      ],
      "metadata": {
        "id": "JgFrNXzOXKqi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model parameters\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_metric = tf.keras.metrics.Mean()\n",
        "bce_loss = tf.keras.losses.BinaryCrossentropy()"
      ],
      "metadata": {
        "id": "JWjRkpxwWCwT"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Helper function to see the progress of the model at the end of every epoch"
      ],
      "metadata": {
        "id": "FqYKdJqFXhUz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_and_save_images(model, epoch, step, test_input):\n",
        "  \"\"\"Helper function to plot our 16 images\n",
        "\n",
        "  Args:\n",
        "\n",
        "  model -- the decoder model\n",
        "  epoch -- current epoch number during training\n",
        "  step -- current step number during training\n",
        "  test_input -- random tensor with shape (16, LATENT_DIM)\n",
        "  \"\"\"\n",
        "\n",
        "  # generate images from the test input\n",
        "  predictions = model.predict(test_input)\n",
        "\n",
        "  # plot the results\n",
        "  fig = plt.figure(figsize=(4,4))\n",
        "\n",
        "  for i in range(predictions.shape[0]):\n",
        "      plt.subplot(4, 4, i+1)\n",
        "      plt.imshow(predictions[i, :, :, 0], cmap='gray')\n",
        "      plt.axis('off')\n",
        "\n",
        "  # tight_layout minimizes the overlap between 2 sub-plots\n",
        "  fig.suptitle(\"epoch: {}, step: {}\".format(epoch, step))\n",
        "  plt.savefig('image_at_epoch_{:04d}_step{:04d}.png'.format(epoch, step))\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "oUGITdayXYTs"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Loop"
      ],
      "metadata": {
        "id": "H2FH49DcX0Zs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# generate random vector as test input to the decoder\n",
        "random_vector_for_generation = tf.random.normal(shape=[16, LATENT_DIM])\n",
        "\n",
        "# number of epochs\n",
        "epochs = 100\n",
        "\n",
        "# initialize the helper function to display outputs from an untrained model\n",
        "generate_and_save_images(decoder, 0, 0, random_vector_for_generation)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  print('Start of epoch %d' % (epoch,))\n",
        "\n",
        "  # iterate over batches\n",
        "  for step, x_batch_train in enumerate(train_dataset):\n",
        "    \n",
        "    with tf.GradientTape() as tape:\n",
        "\n",
        "      # feed a batch to the VAE model\n",
        "      reconstructed = vae(x_batch_train)\n",
        "\n",
        "      # compute reconstruction loss\n",
        "      flattened_inputs = tf.reshape(x_batch_train, shape=[-1])\n",
        "      flattened_outputs = tf.reshape(reconstructed, shape=[-1])\n",
        "      loss = bce_loss(flattened_inputs, flattened_outputs) * 784\n",
        "\n",
        "      # add KLD regularization loss\n",
        "      loss += sum(vae.losses)\n",
        "\n",
        "    # get gradient and update weights\n",
        "    grads = tape.gradient(loss, vae.trainable_weights)\n",
        "    optimizer.apply_gradients(zip(grads, vae.trainable_weights))\n",
        "\n",
        "    # compute the loss metric\n",
        "    loss_metric(loss)\n",
        "\n",
        "    # display outputs every 100 steps\n",
        "    if step % 100 == 0:\n",
        "      display.clear_output(wait=False)\n",
        "      generate_and_save_images(decoder, epoch, step, random_vector_for_generation)\n",
        "      print('Epoch: %s step: %s mean loss = %s' % (epoch, step, loss_metric.result().numpy()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "vorvWZN9XtRT",
        "outputId": "0652f676-be0b-4f32-811c-4df61c9c55f6"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 288x288 with 16 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 15 step: 400 mean loss = 165.24966\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-5fb386160d0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m       \u001b[0;31m# feed a batch to the VAE model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m       \u001b[0mreconstructed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m       \u001b[0;31m# compute reconstruction loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1094\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1095\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1096\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_call_info_injected'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    450\u001b[0m     \"\"\"\n\u001b[1;32m    451\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m--> 452\u001b[0;31m         inputs, training=training, mask=mask)\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1094\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1095\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1096\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_call_info_injected'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/core/tf_op_layer.py\u001b[0m in \u001b[0;36m_call_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0;31m# Decorate the function to produce this layer's call method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     self.call = tf.__internal__.decorator.make_decorator(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/core/tf_op_layer.py\u001b[0m in \u001b[0;36m_call_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwatch_accessed_variables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_variable_creator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m       \u001b[0;31m# We explicitly drop `name` arguments here,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m       \u001b[0;31m# to guard against the case where an op explicitly has a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36mhelper\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0;34m<\u001b[0m\u001b[0mcleanup\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \"\"\"\n\u001b[0;32m--> 237\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhelper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_GeneratorContextManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}